{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import SubplotSpec\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from lightning_pose.utils.frame_selection import get_frames_from_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "df_save_path = \"/media/mattw/behavior/results/pose-estimation/mirror-mouse\"\n",
    "vid_dir = \"/media/mattw/behavior/pose-estimation-data-final/mirror-mouse/videos_test\"\n",
    "dataset_name = \"mirror-mouse\"\n",
    "train_frames = \"75\"\n",
    "\n",
    "models_to_compare = ['baseline', 'semi-super context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_labeled_preds = pd.read_parquet(\n",
    "#     os.path.join(df_save_path, \"%s_labeled_preds.pqt\" % dataset_name))\n",
    "# df_labeled_metrics = pd.read_parquet(\n",
    "#     os.path.join(df_save_path, \"%s_labeled_metrics.pqt\" % dataset_name))\n",
    "df_video_preds = pd.read_parquet(\n",
    "    os.path.join(df_save_path, \"%s_video_preds.pqt\" % dataset_name))\n",
    "df_video_metrics = pd.read_parquet(\n",
    "    os.path.join(df_save_path, \"%s_video_metrics.pqt\" % dataset_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trace_mask(df, video_name, train_frames, model_type, rng_seed, metric_name=None):\n",
    "    mask = ((df.train_frames == train_frames)\n",
    "            & (df.rng_seed_data_pt == rng_seed)\n",
    "            & (df.model_type == model_type)\n",
    "            & (df.video_name == video_name))\n",
    "    if metric_name is not None:\n",
    "        mask = mask & (df.metric == metric_name)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_seed = \"0\"\n",
    "if dataset_name == 'mirror-mouse':\n",
    "    vid_name = '180609_004'\n",
    "    keypoint = 'paw1LH_top'\n",
    "    if train_frames == \"75\":\n",
    "        # slice for traces\n",
    "        time_window = (4700, 4950)\n",
    "        # slice for frames\n",
    "        time_window_frames = (4771, 4774)\n",
    "        # different segment for fig 4\n",
    "#         # slice for traces\n",
    "#         slc = (4500, 4750)\n",
    "#         # slice for frames\n",
    "#         slc_frames = (4530, 4533)\n",
    "#         keypoint = 'paw2LF_top'\n",
    "    elif train_frames == \"1\":\n",
    "        # slice for traces\n",
    "        time_window = (4700, 4950)\n",
    "        # slice for frames\n",
    "        time_window_frames = (4778, 4782)\n",
    "\n",
    "elif dataset_name == 'mirror-fish':\n",
    "    vid_name = '20210129_Quin'\n",
    "    keypoint = 'stripeP_main'\n",
    "    if train_frames == \"75\":\n",
    "        # slice for traces\n",
    "        time_window = (0, 2500)\n",
    "        # slice for frames\n",
    "        time_window_frames = (641, 644)\n",
    "    elif train_frames == \"1\":\n",
    "        # slice for traces\n",
    "        time_window = (0, 2500)\n",
    "        # slice for frames\n",
    "        time_window_frames = (221, 224)\n",
    "        \n",
    "elif dataset_name == 'fly':\n",
    "    vid_name = '2022_01_14_fly2'\n",
    "    keypoint = 'hind-bot'\n",
    "    if train_frames == \"75\":\n",
    "        # slice for traces\n",
    "        time_window = (0, 400)\n",
    "        # slice for frames\n",
    "        time_window_frames = (115, 118)\n",
    "    elif train_frames == \"1\":\n",
    "        # slice for traces\n",
    "        time_window = (0, 400)\n",
    "        # slice for frames\n",
    "        time_window_frames = (250, 253)\n",
    "\n",
    "vid_file = os.path.join(vid_dir, '%s.mp4' % vid_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trace plots for video data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_traces_and_metrics(\n",
    "        df_video_metrics, df_video_preds, models_to_compare, keypoint, vid_name, rng_seed, \n",
    "        time_window, save_file=None):\n",
    "\n",
    "    colors = px.colors.qualitative.Plotly\n",
    "\n",
    "    rows = 3\n",
    "    row_heights = [2, 2, 0.75]\n",
    "    metrics = df_video_metrics.metric.unique()\n",
    "    if \"temporal_norm\" in metrics:\n",
    "        rows += 1\n",
    "        row_heights.insert(0, 0.75)\n",
    "    if \"pca_multiview_error\" in metrics:\n",
    "        rows += 1\n",
    "        row_heights.insert(0, 0.75)\n",
    "    if \"pca_singleview_error\" in metrics:\n",
    "        rows += 1\n",
    "        row_heights.insert(0, 0.75)\n",
    "\n",
    "    fig_traces = make_subplots(\n",
    "        rows=rows, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        x_title=\"Frame number\",\n",
    "        row_heights=row_heights,\n",
    "        vertical_spacing=0.03,\n",
    "    )\n",
    "\n",
    "    yaxis_labels = {}\n",
    "    row = 1\n",
    "\n",
    "    # plot temporal norms\n",
    "    if \"temporal_norm\" in metrics:\n",
    "        for c, model_type in enumerate(models_to_compare):\n",
    "            mask = get_trace_mask(\n",
    "                df_video_metrics, video_name=vid_name, metric_name=\"temporal_norm\",\n",
    "                train_frames=train_frames, model_type=model_type, rng_seed=rng_seed)\n",
    "            fig_traces.add_trace(\n",
    "                go.Scatter(\n",
    "                    name=model_type,\n",
    "                    x=np.arange(time_window[0], time_window[1]),\n",
    "                    y=df_video_metrics[mask][keypoint][slice(*time_window)],\n",
    "                    mode='lines',\n",
    "                    line=dict(color=colors[c]),\n",
    "                    showlegend=False,\n",
    "                ),\n",
    "                row=row, col=1\n",
    "            )\n",
    "        yaxis_labels['yaxis%i' % row] = \"temporal<br>norm\"\n",
    "        row += 1\n",
    "\n",
    "    # plot pca multiview reprojection errors\n",
    "    if \"pca_multiview_error\" in metrics:\n",
    "        for c, model_type in enumerate(models_to_compare):\n",
    "            mask = get_trace_mask(\n",
    "                df_video_metrics, video_name=vid_name, metric_name=\"pca_multiview_error\",\n",
    "                train_frames=train_frames, model_type=model_type, rng_seed=rng_seed)\n",
    "            fig_traces.add_trace(\n",
    "                go.Scatter(\n",
    "                    name=model_type,\n",
    "                    x=np.arange(time_window[0], time_window[1]),\n",
    "                    y=df_video_metrics[mask][keypoint][slice(*time_window)],\n",
    "                    mode='lines',\n",
    "                    line=dict(color=colors[c]),\n",
    "                    showlegend=False,\n",
    "                ),\n",
    "                row=row, col=1\n",
    "            )\n",
    "        yaxis_labels['yaxis%i' % row] = \"pca multi<br>error\"\n",
    "        row += 1\n",
    "\n",
    "    # plot pca singleview reprojection errors\n",
    "    if \"pca_singleview_error\" in metrics:\n",
    "        for c, model_type in enumerate(models_to_compare):\n",
    "            mask = get_trace_mask(\n",
    "                df_video_metrics, video_name=vid_name, metric_name=\"pca_multiview_error\",\n",
    "                train_frames=train_frames, model_type=model_type, rng_seed=rng_seed)\n",
    "            fig_traces.add_trace(\n",
    "                go.Scatter(\n",
    "                    name=model_type,\n",
    "                    x=np.arange(time_window[0], time_window[1]),\n",
    "                    y=df_video_metrics[mask][keypoint][slice(*time_window)],\n",
    "                    mode='lines',\n",
    "                    line=dict(color=colors[c]),\n",
    "                    showlegend=False,\n",
    "                ),\n",
    "                row=row, col=1\n",
    "            )\n",
    "        yaxis_labels['yaxis%i' % row] = \"pca single<br>error\"\n",
    "        row += 1\n",
    "\n",
    "    # plot traces\n",
    "    for coord in [\"x\", \"y\"]:\n",
    "        for c, model_type in enumerate(models_to_compare):\n",
    "            mask = get_trace_mask(\n",
    "                df_video_preds, video_name=vid_name,\n",
    "                train_frames=train_frames, model_type=model_type, rng_seed=rng_seed)\n",
    "            fig_traces.add_trace(\n",
    "                go.Scatter(\n",
    "                    name=model_type,\n",
    "                    x=np.arange(time_window[0], time_window[1]),\n",
    "                    y=df_video_preds[mask].loc[:, (keypoint, coord)][slice(*time_window)],\n",
    "                    mode='lines',\n",
    "                    line=dict(color=colors[c]),\n",
    "                    showlegend=False if coord == \"x\" else True,\n",
    "                ),\n",
    "                row=row, col=1\n",
    "            )\n",
    "        yaxis_labels['yaxis%i' % row] = \"%s coordinate\" % coord\n",
    "        row += 1\n",
    "\n",
    "    # plot likelihoods\n",
    "    for c, model_type in enumerate(models_to_compare):\n",
    "        fig_traces.add_trace(\n",
    "            go.Scatter(\n",
    "                name=model_type,\n",
    "                x=np.arange(time_window[0], time_window[1]),\n",
    "                y=df_video_preds[mask].loc[:, (keypoint, \"likelihood\")][slice(*time_window)],\n",
    "                mode='lines',\n",
    "                line=dict(color=colors[c]),\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            row=row, col=1\n",
    "        )\n",
    "    yaxis_labels['yaxis%i' % row] = \"confidence\"\n",
    "    row += 1\n",
    "\n",
    "    for k, v in yaxis_labels.items():\n",
    "        fig_traces[\"layout\"][k][\"title\"] = v\n",
    "    fig_traces.update_layout(\n",
    "        width=800, height=np.sum(row_heights) * 125,\n",
    "        title_text=\"Timeseries of %s\" % keypoint\n",
    "    )\n",
    "\n",
    "    if save_file is not None:\n",
    "        os.makedirs(os.path.dirname(save_file), exists_ok=True)\n",
    "        fig_traces.write_image(save_file)\n",
    "\n",
    "    fig_traces.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # if save_figs:\n",
    "    #     fig_dir = os.path.join(base_fig_dir, 'fig3_semi-supervised')\n",
    "    #     if not os.path.isdir(fig_dir):\n",
    "    #         os.makedirs(fig_dir)\n",
    "    #     fig_traces.write_image(os.path.join(\n",
    "    #         fig_dir, \n",
    "    #         'traces_%s_%s_%i-%i_tf=%i.pdf' % (\n",
    "    #             dataset_name, keypoint, slc[0], slc[1], train_frames)))\n",
    "save_file = None\n",
    "plot_traces_and_metrics(\n",
    "    df_video_metrics=df_video_metrics, df_video_preds=df_video_preds, \n",
    "    models_to_compare=models_to_compare, keypoint=keypoint, vid_name=vid_name, \n",
    "    rng_seed=rng_seed, time_window=time_window, save_file=save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot a series of frames with markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(vid_file)\n",
    "colors = px.colors.qualitative.Plotly\n",
    "\n",
    "for idx_time in np.arange(time_window_frames[0], time_window_frames[1] + 1):\n",
    "    print(idx_time)\n",
    "    frame = get_frames_from_idxs(cap, [idx_time])\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    \n",
    "    # plot frame\n",
    "    plt.imshow(frame[0, 0], cmap='gray', vmin=0, vmax=255)\n",
    "    \n",
    "    # plot predictions\n",
    "    mask = get_trace_mask(\n",
    "        df_video_preds, video_name=vid_name,\n",
    "        train_frames=train_frames, model_type=models_to_compare[0], rng_seed=rng_seed)\n",
    "    tmp = df_video_preds[mask].iloc[idx_time][keypoint].to_numpy()\n",
    "    plt.plot(tmp[0], tmp[1], '.', markersize=15, color=colors[0])\n",
    "\n",
    "    mask = get_trace_mask(\n",
    "        df_video_preds, video_name=vid_name,\n",
    "        train_frames=train_frames, model_type=models_to_compare[1], rng_seed=rng_seed)\n",
    "    tmp = df_video_preds[mask].iloc[idx_time][keypoint].to_numpy()\n",
    "    plt.plot(tmp[0], tmp[1], '.', markersize=15, color=colors[1])\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.axis('off')\n",
    "    \n",
    "#     if save_figs:\n",
    "#         fig_dir = os.path.join(base_fig_dir, 'fig3_semi-supervised')\n",
    "#         if not os.path.isdir(fig_dir):\n",
    "#             os.makedirs(fig_dir)\n",
    "#         plt.savefig(os.path.join(\n",
    "#             fig_dir,\n",
    "#             'frames_%s_%s_%i_tf=%i.png' % (dataset_name, keypoint, idx_time, train_frames)),\n",
    "#             bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pose",
   "language": "python",
   "name": "pose"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "959d2e27595746213d03c7dd1e0a0dce49dd619fad632ca6324babfdcca64478"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
