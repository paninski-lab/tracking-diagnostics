{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import SubplotSpec\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from diagnostics.paper_utils import get_trace_mask, plot_traces_and_metrics\n",
    "from lightning_pose.utils.frame_selection import get_frames_from_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "\n",
    "dataset_name = \"mirror-fish\"\n",
    "df_save_path = \"/home/mattw/Dropbox/shared/litpose_results/%s\" % dataset_name\n",
    "vid_dir = \"/media/mattw/behavior/pose-estimation-data-final/%s/videos_new\" % dataset_name\n",
    "train_frames = \"75\"\n",
    "\n",
    "models_to_compare = ['baseline', 'semi-super context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_labeled_preds = pd.read_parquet(\n",
    "#     os.path.join(df_save_path, \"%s_labeled_preds.pqt\" % dataset_name))\n",
    "# df_labeled_metrics = pd.read_parquet(\n",
    "#     os.path.join(df_save_path, \"%s_labeled_metrics.pqt\" % dataset_name))\n",
    "df_video_preds = pd.read_parquet(\n",
    "    os.path.join(df_save_path, \"%s_video_preds.pqt\" % dataset_name))\n",
    "df_video_metrics = pd.read_parquet(\n",
    "    os.path.join(df_save_path, \"%s_video_metrics.pqt\" % dataset_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_seed = \"0\"\n",
    "if dataset_name == 'mirror-mouse':\n",
    "#     vid_name = '180609_004'\n",
    "#     vid_name_load = '180609_004'\n",
    "#     keypoint = 'paw1LH_top'\n",
    "#     time_window = (300, 900)\n",
    "#     time_window_frames = (4771, 4774)\n",
    "\n",
    "    vid_name = '180609_004'\n",
    "    vid_name_load = '180609_004'\n",
    "    keypoint = 'paw2LF_top'\n",
    "    time_window = (2800, 3600)\n",
    "    time_window_frames = (4771, 4774)\n",
    "\n",
    "elif dataset_name == 'mirror-fish':\n",
    "    vid_name = '20210129_Quin'\n",
    "    vid_name_load = vid_name\n",
    "    keypoint = 'fork_main'\n",
    "    if train_frames == \"75\":\n",
    "        time_window = (0, 1000)\n",
    "        time_window_frames = (641, 644)\n",
    "    elif train_frames == \"1\":\n",
    "        time_window = (0, 1000)\n",
    "        time_window_frames = (221, 224)\n",
    "        \n",
    "#     vid_name = '20210202_Sean'\n",
    "#     vid_name_load = vid_name\n",
    "#     keypoint = 'dorsal_main'\n",
    "# #     keypoint = 'caudal_v_main'\n",
    "# #     keypoint = 'caudal_d_main'\n",
    "#     if train_frames == \"75\":\n",
    "#         time_window = (500, 3000)\n",
    "#         time_window_frames = (641, 644)\n",
    "        \n",
    "elif dataset_name == 'fly':\n",
    "#     vid_name = '2022_01_05_fly2_sample-1'\n",
    "#     vid_name_load = '2022_01_05_fly2'\n",
    "#     keypoint = 'mid-top'\n",
    "#     if train_frames == \"75\":\n",
    "#         time_window = (50, 250)\n",
    "#         time_window_frames = (115, 118)\n",
    "#     elif train_frames == \"1\":\n",
    "#         time_window = (0, 400)\n",
    "#         time_window_frames = (250, 253)\n",
    "\n",
    "#     vid_name = '2022_01_14_fly1_sample-2'\n",
    "#     vid_name_load = '2022_01_14_fly1'\n",
    "#     keypoint = 'mid-bot'\n",
    "#     time_window = (0, 700)\n",
    "\n",
    "    vid_name = '2022_01_05_fly2_sample-1'\n",
    "    vid_name_load = '2022_01_05_fly2'\n",
    "    keypoint = 'mid-top'\n",
    "    time_window = (100, 400)\n",
    "\n",
    "\n",
    "assert vid_name in df_video_metrics.video_name.unique()\n",
    "vid_file = os.path.join(vid_dir, '%s.mp4' % vid_name_load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trace plots for video data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_video_preds.columns.levels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_video_metrics.video_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save_file = None\n",
    "# for vid_name in df_video_metrics.video_name.unique():\n",
    "#     print(vid_name)\n",
    "#     for keypoint in df_video_preds.columns.levels[0]:\n",
    "# #         if keypoint in [\"model_path\", \"model_type\", \"rng_seed_data_pt\", \"train_frames\", \"video_name\"]:\n",
    "# #             continue\n",
    "#         if keypoint != 'paw2LF_top':\n",
    "#             continue\n",
    "#         else:\n",
    "#             time_window = (0, 5000)\n",
    "#             plot_traces_and_metrics(\n",
    "#                 df_video_metrics=df_video_metrics, df_video_preds=df_video_preds, \n",
    "#                 models_to_compare=models_to_compare, keypoint=keypoint, vid_name=vid_name, \n",
    "#                 train_frames='75', rng_seed=rng_seed, time_window=time_window, \n",
    "#                 save_file=save_file)\n",
    "#             plot_traces_and_metrics(\n",
    "#                 df_video_metrics=df_video_metrics, df_video_preds=df_video_preds, \n",
    "#                 models_to_compare=models_to_compare, keypoint=keypoint, vid_name=vid_name, \n",
    "#                 train_frames='1', rng_seed=rng_seed, time_window=time_window, \n",
    "#                 save_file=save_file)\n",
    "#             print(\"\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # if save_figs:\n",
    "    #     fig_dir = os.path.join(base_fig_dir, 'fig3_semi-supervised')\n",
    "    #     if not os.path.isdir(fig_dir):\n",
    "    #         os.makedirs(fig_dir)\n",
    "    #     fig_traces.write_image(os.path.join(\n",
    "    #         fig_dir, \n",
    "    #         'traces_%s_%s_%i-%i_tf=%i.pdf' % (\n",
    "    #             dataset_name, keypoint, slc[0], slc[1], train_frames)))\n",
    "save_file = None\n",
    "# vid_name = '20210202_Sean'\n",
    "# train_frames = '1'\n",
    "# time_window = (500, 3000)\n",
    "# keypoint = 'dorsal_main'\n",
    "train_frames = '75'\n",
    "plot_traces_and_metrics(\n",
    "    df_video_metrics=df_video_metrics, df_video_preds=df_video_preds, \n",
    "    models_to_compare=models_to_compare, keypoint=keypoint, vid_name=vid_name, \n",
    "    train_frames=train_frames, rng_seed=rng_seed, time_window=time_window, \n",
    "    save_file=save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot a series of frames with markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(vid_file)\n",
    "colors = px.colors.qualitative.Plotly\n",
    "\n",
    "for idx_time in np.arange(time_window_frames[0], time_window_frames[1] + 1):\n",
    "    print(idx_time)\n",
    "    frame = get_frames_from_idxs(cap, [idx_time])\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    \n",
    "    # plot frame\n",
    "    plt.imshow(frame[0, 0], cmap='gray', vmin=0, vmax=255)\n",
    "    \n",
    "    # plot predictions\n",
    "    mask = get_trace_mask(\n",
    "        df_video_preds, video_name=vid_name,\n",
    "        train_frames=train_frames, model_type=models_to_compare[0], rng_seed=rng_seed)\n",
    "    tmp = df_video_preds[mask].iloc[idx_time][keypoint].to_numpy()\n",
    "    plt.plot(tmp[0], tmp[1], '.', markersize=15, color=colors[0])\n",
    "\n",
    "    mask = get_trace_mask(\n",
    "        df_video_preds, video_name=vid_name,\n",
    "        train_frames=train_frames, model_type=models_to_compare[1], rng_seed=rng_seed)\n",
    "    tmp = df_video_preds[mask].iloc[idx_time][keypoint].to_numpy()\n",
    "    plt.plot(tmp[0], tmp[1], '.', markersize=15, color=colors[1])\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.axis('off')\n",
    "    \n",
    "#     if save_figs:\n",
    "#         fig_dir = os.path.join(base_fig_dir, 'fig3_semi-supervised')\n",
    "#         if not os.path.isdir(fig_dir):\n",
    "#             os.makedirs(fig_dir)\n",
    "#         plt.savefig(os.path.join(\n",
    "#             fig_dir,\n",
    "#             'frames_%s_%s_%i_tf=%i.png' % (dataset_name, keypoint, idx_time, train_frames)),\n",
    "#             bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pose",
   "language": "python",
   "name": "pose"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "959d2e27595746213d03c7dd1e0a0dce49dd619fad632ca6324babfdcca64478"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
