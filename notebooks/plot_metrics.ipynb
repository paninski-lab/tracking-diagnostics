{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "\n",
    "from diagnostics.paper_utils import plot_scatters, create_subtitle\n",
    "from diagnostics.paper_utils import plot_metric_bars_and_scatters_labeled\n",
    "from diagnostics.paper_utils import plot_metric_bars_and_scatters_video\n",
    "from diagnostics.paper_utils import plot_metric_vs_pixerror_scatters\n",
    "from diagnostics.paper_utils import plot_metric_vs_metric_scatters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "dataset_name = \"mirror-mouse\"\n",
    "df_save_path = \"/home/mattw/Dropbox/shared/litpose_results/%s\" % dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_labeled_preds = pd.read_parquet(\n",
    "#     os.path.join(df_save_path, \"%s_labeled_preds.pqt\" % dataset_name))\n",
    "df_labeled_metrics = pd.read_parquet(\n",
    "    os.path.join(df_save_path, \"%s_labeled_metrics.pqt\" % dataset_name))\n",
    "# df_video_preds = pd.read_parquet(\n",
    "#     os.path.join(df_save_path, \"%s_video_preds.pqt\" % dataset_name))\n",
    "df_video_metrics = pd.read_parquet(\n",
    "    os.path.join(df_save_path, \"%s_video_metrics.pqt\" % dataset_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots on labeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic metrics for each model type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take mean over points, variability over seeds\n",
    "keypoint = 'mean'\n",
    "split_set = 'test'  # 'test' is only value for which InD and OOD both have results\n",
    "train_frames = '75'  # '75' | '1'   \n",
    "models_to_compare = ['baseline', 'semi-super context']\n",
    "\n",
    "for train_frames in ['1', '75']:\n",
    "    train_frame_str = 'full train frames' if train_frames == '1' \\\n",
    "        else '%s train frames' % train_frames\n",
    "    title = 'Labeled data results on %s dataset (%s)' % (dataset_name, train_frame_str)\n",
    "    plot_metric_bars_and_scatters_labeled(\n",
    "        df_labeled_metrics, models_to_compare, keypoint, train_frames, split_set, pix_thresh=0,\n",
    "        title=title, display_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pixel error vs metric scatters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_to_compare = ['baseline', 'context', 'semi-super', 'semi-super context']\n",
    "for train_frames in ['1', '75']:\n",
    "    train_frame_str = 'full train frames' if train_frames == '1' \\\n",
    "        else '%s train frames' % train_frames\n",
    "    title = 'Labeled data results on %s dataset (%s)' % (dataset_name, train_frame_str)\n",
    "    plot_metric_vs_pixerror_scatters(\n",
    "        df_labeled_metrics, models_to_compare, keypoint, train_frames, split_set, \n",
    "        title=title, display_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confidence vs metric scatters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_to_compare = ['baseline', 'context', 'semi-super', 'semi-super context']\n",
    "for train_frames in ['1', '75']:\n",
    "    train_frame_str = 'full train frames' if train_frames == '1' \\\n",
    "        else '%s train frames' % train_frames\n",
    "    title = 'Labeled data results on %s dataset (%s)' % (dataset_name, train_frame_str)\n",
    "    plot_metric_vs_metric_scatters(\n",
    "        df_labeled_metrics, models_to_compare, keypoint, train_frames, split_set, \n",
    "        title=title, display_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots on unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_video_metrics_gr = df_video_metrics.groupby([\n",
    "    'metric', 'video_name', 'model_path', 'rng_seed_data_pt', 'train_frames', 'model_type']\n",
    ").mean().reset_index().set_index('video_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_compare = ['baseline', 'semi-super context']\n",
    "\n",
    "for train_frames in ['1', '75']:\n",
    "    train_frame_str = 'full train frames' if train_frames == '1' \\\n",
    "        else '%s train frames' % train_frames\n",
    "    title = 'Video results on %s dataset (%s)' % (dataset_name, train_frame_str)\n",
    "    plot_metric_bars_and_scatters_video(\n",
    "        df_video_metrics_gr, models_to_compare, keypoint, train_frames,\n",
    "        title=title, display_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pose",
   "language": "python",
   "name": "pose"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "959d2e27595746213d03c7dd1e0a0dce49dd619fad632ca6324babfdcca64478"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
