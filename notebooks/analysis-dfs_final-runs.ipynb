{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from diagnostics.inventory import ModelInventoryBuilder, QueryBuilder\n",
    "from diagnostics.inventory import load_metric_csv, load_confidence_csv\n",
    "from diagnostics.paper_utils import update_col_names, get_video_names, add_model_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt to specify directory containing config files\n",
    "artifacts_path = \"/media/mattw/behavior/results/pose-estimation/mirror-mouse/2022-11-17\"\n",
    "df_save_path = \"/media/mattw/behavior/results/pose-estimation/mirror-mouse\"\n",
    "dataset_name = \"mirror-mouse\"\n",
    "\n",
    "rng_seeds_list =  [\"0\", \"1\"]\n",
    "train_frames_list = [\"75\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model registry from 8 configs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 63.86it/s]\n"
     ]
    }
   ],
   "source": [
    "model_inventory = ModelInventoryBuilder(artifacts_path)\n",
    "total_df = model_inventory.build_dframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`training.rng_seed_data_pt` == '0' or `training.rng_seed_data_pt` == '1'\n",
      "`training.train_frames` == '75'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8, 92)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_builder = QueryBuilder(total_df)\n",
    "query_builder.add_query(\"training.rng_seed_data_pt\", \"in\", rng_seeds_list)\n",
    "query_builder.add_query(\"training.train_frames\", \"in\", train_frames_list)\n",
    "# query_builder.add_query(\"model.losses_to_use\", \"in\", [\"[]\", \"[pca_multiview]\"]) # trying to grab both unimodal_mse and supervised. note no quotes inside brackets per loss\n",
    "query_builder.add_timestamp_query(\"2022-11-16\", \"2022-11-20\") # works\n",
    "# query_builder.add_query(\"losses.pca_multiview.log_weight\", \">\", 4.) \n",
    "\n",
    "total_df_queried = total_df.query(query_builder.combine_queries(\"and\"))\n",
    "total_df_queried.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:05,  1.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# loop over rows of df, load predictions_pixel_error.csv, predictions_pca_singleview_error.csv\n",
    "df_labeled_preds = []\n",
    "df_labeled_metrics = []\n",
    "df_video_preds = []\n",
    "df_video_metrics = []\n",
    "for i, model in tqdm(total_df_queried.iterrows()):\n",
    "    \n",
    "    # --------------------\n",
    "    # labeled predictions\n",
    "    # --------------------\n",
    "    df_labeled_preds_curr = []\n",
    "    for distribution_type in [\"InD\", \"OOD\"]:\n",
    "        if distribution_type == \"InD\":\n",
    "            filename = os.path.join(model[\"path\"], \"predictions.csv\")\n",
    "        else:\n",
    "            filename = os.path.join(model[\"path\"], \"predictions_new.csv\")\n",
    "        df = pd.read_csv(filename, header=[1, 2], index_col=0)\n",
    "        df = update_col_names(df)\n",
    "        df.loc[:, (\"distribution\", \"\")] = distribution_type\n",
    "        if distribution_type == \"OOD\":\n",
    "            df.loc[:, (\"set\", \"\")] = \"test\"\n",
    "        df_labeled_preds_curr.append(df)\n",
    "    df_labeled_preds_curr = pd.concat(df_labeled_preds_curr)\n",
    "    add_model_metadata(df_labeled_preds_curr, model, levels=2)\n",
    "    df_labeled_preds.append(df_labeled_preds_curr)\n",
    "    \n",
    "    # --------------------\n",
    "    # labeled metrics\n",
    "    # --------------------\n",
    "    df_labeled_metrics_curr = []\n",
    "    for distribution_type in [\"InD\", \"OOD\"]:\n",
    "        # load precomputed errors\n",
    "        for metric_name in [\"pixel_error\", \"pca_singleview_error\", \"pca_multiview_error\"]:\n",
    "            if distribution_type == \"InD\":\n",
    "                filename = os.path.join(model[\"path\"], \"predictions_%s.csv\" % metric_name)\n",
    "            else:\n",
    "                filename = os.path.join(model[\"path\"], \"predictions_new_%s.csv\" % metric_name)\n",
    "            if os.path.isfile(filename):\n",
    "                df = load_metric_csv(\n",
    "                    filename, metric_name, None, pd_kwargs={\"header\": [0], \"index_col\": 0})\n",
    "                df[\"distribution\"] = distribution_type\n",
    "                if distribution_type == \"OOD\":\n",
    "                    df[\"set\"] = \"test\"\n",
    "                df_labeled_metrics_curr.append(df)\n",
    "        # load confidences from predictions\n",
    "        if distribution_type == \"InD\":\n",
    "            filename = os.path.join(model[\"path\"], \"predictions.csv\")\n",
    "        else:\n",
    "            filename = os.path.join(model[\"path\"], \"predictions_new.csv\")\n",
    "        df = load_confidence_csv(filename)\n",
    "        df[\"distribution\"] = distribution_type\n",
    "        if distribution_type == \"OOD\":\n",
    "            df[\"set\"] = \"test\"\n",
    "        df_labeled_metrics_curr.append(df)\n",
    "    df_labeled_metrics_curr = pd.concat(df_labeled_metrics_curr)\n",
    "    add_model_metadata(df_labeled_metrics_curr, model, levels=1)\n",
    "    df_labeled_metrics.append(df_labeled_metrics_curr)\n",
    "\n",
    "    # --------------------\n",
    "    # video predictions\n",
    "    # --------------------\n",
    "    video_names = get_video_names(os.listdir(os.path.join(model[\"path\"], \"video_preds\")))\n",
    "    df_video_preds_curr = []\n",
    "    for video_name in video_names:\n",
    "        filename = os.path.join(model[\"path\"], \"video_preds\", \"%s.csv\" % video_name)\n",
    "        df = pd.read_csv(filename, header=[1, 2], index_col=0)\n",
    "        df.loc[:, (\"video_name\", \"\")] = video_name\n",
    "        df_video_preds_curr.append(df)\n",
    "    df_video_preds_curr = pd.concat(df_video_preds_curr)\n",
    "    add_model_metadata(df_video_preds_curr, model, levels=2)  # in-place\n",
    "    df_video_preds.append(df_video_preds_curr)\n",
    "\n",
    "    # --------------------\n",
    "    # video metrics\n",
    "    # --------------------\n",
    "    video_names = get_video_names(os.listdir(os.path.join(model[\"path\"], \"video_preds\")))\n",
    "    df_video_metrics_curr = []\n",
    "    for video_name in video_names:\n",
    "        # load precomputed metrics\n",
    "        for metric_name in [\"temporal_norm\", \"pca_singleview_error\", \"pca_multiview_error\"]:\n",
    "            filename = os.path.join(\n",
    "                model[\"path\"], \"video_preds\", \"%s_%s.csv\" % (video_name, metric_name))\n",
    "            df = load_metric_csv(\n",
    "                filename, metric_name, None, pd_kwargs={\"header\": [0], \"index_col\": 0})\n",
    "            df[\"video_name\"] = video_name\n",
    "            df_video_metrics_curr.append(df)\n",
    "        # load confidences from predictions\n",
    "        filename = os.path.join(model[\"path\"], \"video_preds\", \"%s.csv\" % video_name)\n",
    "        df = load_confidence_csv(filename)\n",
    "        df[\"video_name\"] = video_name\n",
    "        df_video_metrics_curr.append(df)\n",
    "    df_video_metrics_curr = pd.concat(df_video_metrics_curr)\n",
    "    add_model_metadata(df_video_metrics_curr, model, levels=1)  # in-place\n",
    "    df_video_metrics.append(df_video_metrics_curr)\n",
    "    \n",
    "# concat all dfs\n",
    "df_labeled_preds = pd.concat(df_labeled_preds)\n",
    "df_labeled_metrics = pd.concat(df_labeled_metrics)\n",
    "df_video_preds = pd.concat(df_video_preds)\n",
    "df_video_metrics = pd.concat(df_video_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save out dfs\n",
    "df_labeled_preds.to_parquet(os.path.join(df_save_path, \"%s_labeled_preds.pqt\" % dataset_name))\n",
    "df_labeled_metrics.to_parquet(os.path.join(df_save_path, \"%s_labeled_metrics.pqt\" % dataset_name))\n",
    "df_video_preds.to_parquet(os.path.join(df_save_path, \"%s_video_preds.pqt\" % dataset_name))\n",
    "df_video_metrics.to_parquet(os.path.join(df_save_path, \"%s_video_metrics.pqt\" % dataset_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pose",
   "language": "python",
   "name": "pose"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "959d2e27595746213d03c7dd1e0a0dce49dd619fad632ca6324babfdcca64478"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
